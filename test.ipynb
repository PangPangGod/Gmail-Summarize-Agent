{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import GmailToolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.gmail.utils import (\n",
    "    build_resource_service,\n",
    "    get_gmail_credentials,\n",
    ")\n",
    "\n",
    "credentials = get_gmail_credentials(\n",
    "    token_file=\"token.json\",\n",
    "    scopes=[\"https://mail.google.com/\"],\n",
    "    client_secrets_file=\"credentials.json\",\n",
    ")\n",
    "api_resource = build_resource_service(credentials=credentials)\n",
    "\n",
    "toolkit = GmailToolkit(api_resource=api_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GmailCreateDraft(api_resource=<googleapiclient.discovery.Resource object at 0x000002598E635F00>),\n",
       " GmailSendMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002598E635F00>),\n",
       " GmailSearch(api_resource=<googleapiclient.discovery.Resource object at 0x000002598E635F00>),\n",
       " GmailGetMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002598E635F00>),\n",
       " GmailGetThread(api_resource=<googleapiclient.discovery.Resource object at 0x000002598E635F00>)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = toolkit.get_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'instructions': 'You are an assistant. return output only.'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instructions'], template='{instructions}')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "instructions = \"\"\"You are an assistant. return output only.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ChatOpenAI.bind_functions of ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002598FFA9600>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002598FFE0370>, model_name='gpt-3.5-turbo-0125', temperature=0.0, openai_api_key='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', openai_proxy='', streaming=True, max_tokens=2048)>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, streaming=True, max_tokens=2048)\n",
    "agent = create_openai_functions_agent(llm, toolkit.get_tools(), prompt)\n",
    "\n",
    "llm.bind_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=toolkit.get_tools(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = agent_executor.invoke({\"input\": \"`search_gmail` with `{'query': 'from':'Medium Daily Digest', 'max_results': 1}`. return Most recent id formed with json format..\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"18d85ba63be5cf84\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '18d85ba63be5cf84'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "print(search_result[\"output\"])\n",
    "\n",
    "search_result_output = json.loads(search_result[\"output\"])\n",
    "search_result_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "import base64\n",
    "import email\n",
    "import os\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_credentials():\n",
    "    creds = None\n",
    "    # token.json ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÎ©¥, Ïù¥ÎØ∏ Ïù∏Ï¶ùÎêú ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥Î•º Î∂àÎü¨ÏòµÎãàÎã§.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # ÏÇ¨Ïö©Ïûê Ïù∏Ï¶ùÏù¥ ÌïÑÏöîÌïú Í≤ΩÏö∞\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Îã§Ïùå Î≤à ÏÇ¨Ïö©ÏùÑ ÏúÑÌï¥ Ïù∏Ï¶ùÎêú ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥Î•º Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "creds = create_credentials()\n",
    "service = build('gmail', 'v1', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message snippet: Rhcp Stories for Rhcp @rhcp1134¬∑Become a member Medium daily digest Today&#39;s highlights Cobus Greyling Cobus Greyling¬∑ 5 min read Corrective RAG (CRAG) By now, RAG is an accepted and well\n"
     ]
    }
   ],
   "source": [
    "def get_message(service, user_id, message_id):\n",
    "    try:\n",
    "        message = service.users().messages().get(userId=user_id, id=message_id, format='raw').execute()\n",
    "        print('Message snippet: %s' % message['snippet'])\n",
    "\n",
    "        msg_str = base64.urlsafe_b64decode(message['raw'].encode('ASCII'))\n",
    "        mime_msg = email.message_from_bytes(msg_str)\n",
    "\n",
    "        # Î©îÏùº Î≥∏Î¨∏ Ï∞æÍ∏∞\n",
    "        if mime_msg.is_multipart():\n",
    "            for part in mime_msg.walk():\n",
    "                if part.get_content_type() == 'text/html':\n",
    "                    html_content = part.get_payload(decode=True).decode()\n",
    "                    break\n",
    "        else:\n",
    "            html_content = mime_msg.get_payload(decode=True).decode()\n",
    "\n",
    "        return html_content\n",
    "    except Exception as error:\n",
    "        print('An error occurred: %s' % error)\n",
    "\n",
    "# Î©îÏùº ÎÇ¥Ïö© Í∞ÄÏ†∏Ïò§Í∏∞ Î∞è ÌååÏã± ÏòàÏ†ú\n",
    "user_id = 'me'  # ÌòÑÏû¨ Î°úÍ∑∏Ïù∏Ìïú ÏÇ¨Ïö©Ïûê\n",
    "message_id = search_result_output[\"id\"]  # Í∞ÄÏ†∏Ïò§Í≥†Ïûê ÌïòÎäî Î©îÏãúÏßÄÏùò ID\n",
    "html_content = get_message(service, user_id, message_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "doc = Document(page_content=html_content)\n",
    "\n",
    "bs = BeautifulSoupTransformer()\n",
    "bs_content = bs.transform_documents(documents=[doc], tags_to_extract=[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories for (https://medium.com/@rhcp1134?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Rhcp @rhcp1134 (https://medium.com/@rhcp1134?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Become a member (https://medium.com/plans?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Cobus Greyling (https://medium.com/@cobusgreyling?source=email-2483a20590b9-1707327775011-digest.reader--5e40467099f8----0-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Corrective RAG (CRAG) By now, RAG is an accepted and well established standard for addressing data relevance for in-context‚Ä¶ James Presbitero Jr. (https://medium.com/@jamespresbiterojr?source=email-2483a20590b9-1707327775011-digest.reader-b9c709a27d5e-9b04f399d88c----1-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Practice in Public (https://medium.com/practice-in-public?source=email-2483a20590b9-1707327775011-digest.reader-b9c709a27d5e-9b04f399d88c----1-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) These Words Make it Obvious That Your Text is Written By AI These 7 words are painfully obvious. They make me cringe. They will make your reader cringe. Citizen Reader (https://medium.com/@sarahcords?source=email-2483a20590b9-1707327775011-digest.reader-b163f398200c-996f37264bcf----2-108------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Ellemeno (https://medium.com/ellemeno?source=email-2483a20590b9-1707327775011-digest.reader-b163f398200c-996f37264bcf----2-108------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Desperately Seeking Discipline And no, sadly, not the fun kinky type Marc Llopart (https://medium.com/@marcllopart?source=email-2483a20590b9-1707327775011-digest.reader-3fe99b2acc4-a57e196aff20----3-102------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) AI Advances (https://medium.com/ai-advances?source=email-2483a20590b9-1707327775011-digest.reader-3fe99b2acc4-a57e196aff20----3-102------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) From text and images to Chat: Transforming data into conversations with‚Ä¶ Transform text & images into chat: unleash AI with Pinecone & LangChain for dynamic data conversations. Florian June (https://medium.com/@florian_algo?source=email-2483a20590b9-1707327775011-digest.reader-78d064101951-84756b82dca7----4-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Artificial Intelligence in Plain English (https://medium.com/ai-in-plain-english?source=email-2483a20590b9-1707327775011-digest.reader-78d064101951-84756b82dca7----4-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Advanced RAG 03: Using RAGAs + LlamaIndex for RAG evaluation In this article, we first introduce evaluation metrics for RAG proposed by RAGAs(Retrieval Augmented‚Ä¶ Zain Baquar (https://medium.com/@zainbaq?source=email-2483a20590b9-1707327775011-digest.reader-7f60cf5620c9-63fdfefaa888----5-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Towards Data Science (https://medium.com/towards-data-science?source=email-2483a20590b9-1707327775011-digest.reader-7f60cf5620c9-63fdfefaa888----5-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) QueryGPT‚Ää‚Äî‚ÄäHarnessing Generative AI To Query Your Data With Natural Language. A prototype tool powered by Large Language Models to make querying your databases as easy as saying the word. Gao Dalie (È´òÈÅîÁÉà) (https://medium.com/@GaoDalie_AI?source=email-2483a20590b9-1707327775011-digest.reader-5517fd7b58a6-79c1473086b8----6-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Level Up Coding (https://medium.com/gitconnected?source=email-2483a20590b9-1707327775011-digest.reader-5517fd7b58a6-79c1473086b8----6-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) LangGraph + Gemini Pro + Custom Tool + Streamlit = Multi-Agent Application‚Ä¶ In this post, you are going to learn how we can create this chatbot in LangGraph, Gemini Pro or any model you‚Ä¶ zhaozhiming (https://medium.com/@zhaozhiming?source=email-2483a20590b9-1707327775011-digest.reader-440100e76000-9fad3bf352b6----7-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Generative AI (https://medium.com/generative-ai?source=email-2483a20590b9-1707327775011-digest.reader-440100e76000-9fad3bf352b6----7-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Evaluating RAG Applications with Trulens Currently, Retrieval Augmented Generation (RAG) applications based on Large Language Models (LLMs) are widely‚Ä¶ Giuseppe Futia (https://medium.com/@giuseppefutia?source=email-2483a20590b9-1707327775011-digest.reader--0dfc39d2a893----8-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Building KGs with LLMs‚Ää‚Äî‚ÄäThe Use Case of the Rockefeller Archive Center How we used GPT to perform Named Entity Recognition, Relation Extraction, and Entity Resolution on‚Ä¶ Chandan Durgia (https://medium.com/@durgiachandan?source=email-2483a20590b9-1707327775011-digest.reader--1fd9f64454a9----9-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Embedding: Types, Use cases and Evaluation (Part 3 of RAG Series) Making computers understand Text Alex Mathers (https://medium.com/@iamalexmathers?source=email-2483a20590b9-1707327775011-digest.reader--c3d5b3799c94----10-99------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Five ways you can be immune to the AI ‚Äòthreat‚Äô in the coming years Don‚Äôt wake up in five years without income because A.I. Richardson stole your job. Sandeep Chavan (https://medium.com/@schavan_68898?source=email-2483a20590b9-1707327775011-digest.reader-e48f673dd523-d61e69702648----11-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Paktolus Engineering (https://medium.com/paktolus-engineering?source=email-2483a20590b9-1707327775011-digest.reader-e48f673dd523-d61e69702648----11-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Revolutionising Information Retrieval with Generative AI (Text-to-SQL) Introduction Suman Das (https://medium.com/@dassum?source=email-2483a20590b9-1707327775011-digest.reader--fb60abdeba07----12-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRA The field of natural language processing has been revolutionized by large language models (LLMs), which‚Ä¶ Venkat Ram Rao (https://medium.com/@venkat.ramrao?source=email-2483a20590b9-1707327775011-digest.reader--981c732e92b0----13-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Training an LLM Re-Ranker using Direct Preference Optimization Training Mistral 7B to be an LLM Re-ranker using human feedback. Edit who you follow (https://medium.com/me/following/people?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-31) LlamaIndex Newsletter 2024‚Äì01‚Äì30 Hello LlamaIndex Adventurers ü¶ô, LlamaIndex LlamaIndex Blog (https://medium.com/llamaindex-blog?source=email-2483a20590b9-1707327775011-digest.reader-d7683ed5043e-0d01eb0d8cef----0-2------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-31) Control your recommendations (https://medium.com/me/missioncontrol?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Medium (https://medium.com/?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Unsubscribe (https://medium.com/me/email-settings/2483a20590b9/70e1f54132fc?type=social&source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Switch to the Weekly Digest (https://medium.com/me/email-settings/2483a20590b9/70e1f54132fc?type=social&preference=2&source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Careers (https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Help Center (https://help.medium.com/hc/en-us?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Privacy Policy (https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Terms of service (https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f)\n"
     ]
    }
   ],
   "source": [
    "for page in bs_content:\n",
    "    print(page.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# BeautifulSoup Í∞ùÏ≤¥Î•º ÏÉùÏÑ±ÌïòÏó¨ HTMLÏùÑ ÌååÏã±Ìï©ÎãàÎã§.\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Î™®Îì† <a> ÌÉúÍ∑∏Î•º Ï∞æÍ≥† Îëê Î≤àÏß∏ <a> ÌÉúÍ∑∏Î•º ÏÑ†ÌÉùÌï©ÎãàÎã§.\n",
    "links = soup.find_all('a')\n",
    "\n",
    "# for link in links:\n",
    "#     print(link)\n",
    "#     print(type(link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrective RAG (CRAG)By now, RAG is an accepted and well established standard for addressing data relevance for in-context‚Ä¶\n",
      "url : https://medium.com/@cobusgreyling/corrective-rag-crag-5e40467099f8\n",
      "These Words Make it Obvious That Your Text is Written By AIThese 7 words are painfully obvious. They make me cringe. They will make your reader cringe.\n",
      "url : https://medium.com/@jamespresbiterojr/these-words-make-it-obvious-that-your-text-is-written-by-ai-9b04f399d88c\n",
      "Desperately Seeking DisciplineAnd no, sadly, not the fun kinky type\n",
      "url : https://medium.com/@sarahcords/desperately-seeking-discipline-996f37264bcf\n",
      "From text and images to Chat: Transforming data into conversations with‚Ä¶Transform text & images into chat: unleash AI with Pinecone & LangChain for dynamic data conversations.\n",
      "url : https://medium.com/@marcllopart/from-text-and-images-to-chat-transforming-data-into-conversations-with-pinecone-and-langchain-a57e196aff20\n",
      "Advanced RAG 03: Using RAGAs + LlamaIndex for RAG evaluationIn this article, we first introduce evaluation metrics for RAG proposed by RAGAs(Retrieval Augmented‚Ä¶\n",
      "url : https://medium.com/@florian_algo/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7\n",
      "QueryGPT‚Ää‚Äî‚ÄäHarnessing Generative AI To Query Your Data With Natural Language.A prototype tool powered by Large Language Models to make querying your databases as easy as saying the word.\n",
      "url : https://medium.com/@zainbaq/querygpt-harnessing-generative-ai-to-query-your-data-with-natural-language-63fdfefaa888\n",
      "LangGraph + Gemini Pro + Custom Tool + Streamlit = Multi-Agent Application‚Ä¶In this post, you are going to learn how we can create this chatbot in LangGraph, Gemini Pro or any model you‚Ä¶\n",
      "url : https://medium.com/@GaoDalie_AI/langgraph-gemini-pro-custom-tool-streamlit-multi-agent-application-development-79c1473086b8\n",
      "Evaluating RAG Applications with TrulensCurrently, Retrieval Augmented Generation (RAG) applications based on Large Language Models (LLMs) are widely‚Ä¶\n",
      "url : https://medium.com/@zhaozhiming/evaluating-rag-applications-with-trulens-9fad3bf352b6\n",
      "Building KGs with LLMs‚Ää‚Äî‚ÄäThe Use Case of the Rockefeller Archive CenterHow we used GPT to perform Named Entity Recognition, Relation Extraction, and Entity Resolution on‚Ä¶\n",
      "url : https://medium.com/@giuseppefutia/building-kgs-with-llms-the-use-case-of-the-rockefeller-archive-center-0dfc39d2a893\n",
      "Embedding: Types, Use cases and Evaluation (Part 3 of RAG Series)Making computers understand Text\n",
      "url : https://medium.com/@durgiachandan/embedding-types-use-cases-and-evaluation-part-3-of-rag-series-1fd9f64454a9\n",
      "Five ways you can be immune to the AI ‚Äòthreat‚Äô in the coming yearsDon‚Äôt wake up in five years without income because A.I. Richardson stole your job.\n",
      "url : https://medium.com/@iamalexmathers/five-ways-you-can-be-immune-to-the-ai-threat-in-the-coming-years-c3d5b3799c94\n",
      "Revolutionising Information Retrieval with Generative AI (Text-to-SQL)Introduction\n",
      "url : https://medium.com/@schavan_68898/revolutionising-information-retrieval-with-generative-ai-text-to-sql-d61e69702648\n",
      "Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRAThe field of natural language processing has been revolutionized by large language models (LLMs), which‚Ä¶\n",
      "url : https://medium.com/@dassum/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07\n",
      "Training an LLM Re-Ranker using Direct Preference OptimizationTraining Mistral 7B to be an LLM Re-ranker using human feedback.\n",
      "url : https://medium.com/@venkat.ramrao/training-an-llm-re-ranker-using-direct-preference-optimization-981c732e92b0\n",
      "LlamaIndex Newsletter 2024‚Äì01‚Äì30Hello LlamaIndex Adventurers ü¶ô,\n",
      "url : https://medium.com/@llama_index/llamaindex-newsletter-2024-01-30-0d01eb0d8cef\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# BeautifulSoup Í∞ùÏ≤¥Î•º ÏÉùÏÑ±ÌïòÏó¨ HTMLÏùÑ ÌååÏã±Ìï©ÎãàÎã§.\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Î™®Îì† <a> ÌÉúÍ∑∏Î•º Ï∞æÏäµÎãàÎã§.\n",
    "links = soup.find_all('a')\n",
    "\n",
    "def validation(url):\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    if parsed_url.scheme == \"https\" and parsed_url.netloc == \"medium.com\":\n",
    "            # Í≤ΩÎ°úÏóêÏÑú @username ÌôïÏù∏\n",
    "            path_parts = parsed_url.path.split('/')\n",
    "            if len(path_parts) >= 3 and path_parts[1].startswith('@'):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "url_dict = {}\n",
    "\n",
    "for link in links:\n",
    "    text = link.get_text(strip=True)\n",
    "    url = link.get('href').split(\"?\")[0]\n",
    "\n",
    "    if validation(url):\n",
    "        url_dict[url] = text\n",
    "    \n",
    "for key, value in url_dict.items():\n",
    "     print(f\"{value}\")\n",
    "     print(f\"url : {key}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class URL_TABLE(BaseModel):\n",
    "    url:str = Field(description=\"url\")\n",
    "    description:str = Field(description=\"description that describe url\")\n",
    "\n",
    "class URLTextList(BaseModel):\n",
    "    url_text_pairs: List[URL_TABLE]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=URLTextList)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = llm | parser\n",
    "\n",
    "result = chain.invoke(f\"\"\"get dict {url_dict}. Show value and url if it is related to LLM or Python or Programming.\n",
    "    Output should be dictionary like this .\n",
    "    <Example output>                       \n",
    "                     {{\n",
    "    \"url_text_pairs\": [\n",
    "        {{\n",
    "            \"url\": \"https://example.com/1\",\n",
    "            \"description\": \"Example description 1\"\n",
    "        }},\n",
    "        {{\n",
    "            \"url\": \"https://example.com/2\",\n",
    "            \"description\": \"Example description 2\"\n",
    "        }}\n",
    "    ]}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url='https://medium.com/@cobusgreyling/corrective-rag-crag-5e40467099f8' description='Corrective RAG (CRAG)By now, RAG is an accepted and well established standard for addressing data relevance for in-context‚Ä¶'\n",
      "url='https://medium.com/@marcllopart/from-text-and-images-to-chat-transforming-data-into-conversations-with-pinecone-and-langchain-a57e196aff20' description='From text and images to Chat: Transforming data into conversations with‚Ä¶Transform text & images into chat: unleash AI with Pinecone & LangChain for dynamic data conversations.'\n",
      "url='https://medium.com/@florian_algo/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7' description='Advanced RAG 03: Using RAGAs + LlamaIndex for RAG evaluationIn this article, we first introduce evaluation metrics for RAG proposed by RAGAs(Retrieval Augmented‚Ä¶'\n",
      "url='https://medium.com/@dassum/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07' description='Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRAThe field of natural language processing has been revolutionized by large language models (LLMs), which‚Ä¶'\n",
      "url='https://medium.com/@venkat.ramrao/training-an-llm-re-ranker-using-direct-preference-optimization-981c732e92b0' description='Training an LLM Re-Ranker using Direct Preference OptimizationTraining Mistral 7B to be an LLM Re-ranker using human feedback.'\n"
     ]
    }
   ],
   "source": [
    "for content in result.url_text_pairs:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
