{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "import base64\n",
    "import email\n",
    "import os\n",
    "\n",
    "from langchain_community.agent_toolkits import GmailToolkit\n",
    "from langchain_community.tools.gmail.utils import (\n",
    "    build_resource_service,\n",
    ")\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "\n",
    "def create_credentials():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # 사용자 인증이 필요한 경우\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # 다음 번 사용을 위해 인증된 사용자 정보를 저장\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "creds = create_credentials()\n",
    "api_resource = build_resource_service(credentials=creds)\n",
    "service = build('gmail', 'v1', credentials=creds)\n",
    "toolkit = GmailToolkit(api_resource=api_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GmailCreateDraft(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailSendMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailSearch(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailGetMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailGetThread(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = toolkit.get_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "instructions = \"\"\"You are an assistant. return output only.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, streaming=True, max_tokens=2048)\n",
    "agent = create_openai_functions_agent(llm, toolkit.get_tools(), prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=toolkit.get_tools(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent matching email ID: 18d85ba63be5cf84\n"
     ]
    }
   ],
   "source": [
    "search_result = agent_executor.invoke({\"input\": \"`search_gmail` with `{'query': 'from':'Medium Daily Digest', 'max_results': 1}`. Return Most recent matching mail with id ONLY.\"})\n",
    "print(search_result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18d85ba63be5cf84\n"
     ]
    }
   ],
   "source": [
    "search_result_output = search_result[\"output\"].split(\":\")[-1].lstrip(\" \") # parse result\n",
    "print(search_result_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message snippet: Rhcp Stories for Rhcp @rhcp1134·Become a member Medium daily digest Today&#39;s highlights Cobus Greyling Cobus Greyling· 5 min read Corrective RAG (CRAG) By now, RAG is an accepted and well\n"
     ]
    }
   ],
   "source": [
    "def get_message(service, user_id, message_id):\n",
    "    try:\n",
    "        message = service.users().messages().get(userId=user_id, id=message_id, format='raw').execute()\n",
    "        print('Message snippet: %s' % message['snippet'])\n",
    "\n",
    "        msg_str = base64.urlsafe_b64decode(message['raw'].encode('ASCII'))\n",
    "        mime_msg = email.message_from_bytes(msg_str)\n",
    "\n",
    "        # 메일 본문 찾기\n",
    "        if mime_msg.is_multipart():\n",
    "            for part in mime_msg.walk():\n",
    "                if part.get_content_type() == 'text/html':\n",
    "                    html_content = part.get_payload(decode=True).decode()\n",
    "                    break\n",
    "        else:\n",
    "            html_content = mime_msg.get_payload(decode=True).decode()\n",
    "\n",
    "        return html_content\n",
    "    except Exception as error:\n",
    "        print('An error occurred: %s' % error)\n",
    "\n",
    "# 메일 내용 가져오기 및 파싱 예제\n",
    "user_id = 'me'  # 현재 로그인한 사용자\n",
    "message_id = search_result_output  # 가져오고자 하는 메시지의 ID\n",
    "html_content = get_message(service, user_id, message_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "doc = Document(page_content=html_content)\n",
    "bs = BeautifulSoupTransformer()\n",
    "bs_content = bs.transform_documents(documents=[doc], tags_to_extract=[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories for (https://medium.com/@rhcp1134?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Rhcp @rhcp1134 (https://medium.com/@rhcp1134?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Become a member (https://medium.com/plans?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Cobus Greyling (https://medium.com/@cobusgreyling?source=email-2483a20590b9-1707327775011-digest.reader--5e40467099f8----0-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Corrective RAG (CRAG) By now, RAG is an accepted and well established standard for addressing data relevance for in-context… James Presbitero Jr. (https://medium.com/@jamespresbiterojr?source=email-2483a20590b9-1707327775011-digest.reader-b9c709a27d5e-9b04f399d88c----1-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Practice in Public (https://medium.com/practice-in-public?source=email-2483a20590b9-1707327775011-digest.reader-b9c709a27d5e-9b04f399d88c----1-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) These Words Make it Obvious That Your Text is Written By AI These 7 words are painfully obvious. They make me cringe. They will make your reader cringe. Citizen Reader (https://medium.com/@sarahcords?source=email-2483a20590b9-1707327775011-digest.reader-b163f398200c-996f37264bcf----2-108------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Ellemeno (https://medium.com/ellemeno?source=email-2483a20590b9-1707327775011-digest.reader-b163f398200c-996f37264bcf----2-108------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Desperately Seeking Discipline And no, sadly, not the fun kinky type Marc Llopart (https://medium.com/@marcllopart?source=email-2483a20590b9-1707327775011-digest.reader-3fe99b2acc4-a57e196aff20----3-102------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) AI Advances (https://medium.com/ai-advances?source=email-2483a20590b9-1707327775011-digest.reader-3fe99b2acc4-a57e196aff20----3-102------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) From text and images to Chat: Transforming data into conversations with… Transform text & images into chat: unleash AI with Pinecone & LangChain for dynamic data conversations. Florian June (https://medium.com/@florian_algo?source=email-2483a20590b9-1707327775011-digest.reader-78d064101951-84756b82dca7----4-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Artificial Intelligence in Plain English (https://medium.com/ai-in-plain-english?source=email-2483a20590b9-1707327775011-digest.reader-78d064101951-84756b82dca7----4-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Advanced RAG 03: Using RAGAs + LlamaIndex for RAG evaluation In this article, we first introduce evaluation metrics for RAG proposed by RAGAs(Retrieval Augmented… Zain Baquar (https://medium.com/@zainbaq?source=email-2483a20590b9-1707327775011-digest.reader-7f60cf5620c9-63fdfefaa888----5-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Towards Data Science (https://medium.com/towards-data-science?source=email-2483a20590b9-1707327775011-digest.reader-7f60cf5620c9-63fdfefaa888----5-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) QueryGPT — Harnessing Generative AI To Query Your Data With Natural Language. A prototype tool powered by Large Language Models to make querying your databases as easy as saying the word. Gao Dalie (高達烈) (https://medium.com/@GaoDalie_AI?source=email-2483a20590b9-1707327775011-digest.reader-5517fd7b58a6-79c1473086b8----6-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Level Up Coding (https://medium.com/gitconnected?source=email-2483a20590b9-1707327775011-digest.reader-5517fd7b58a6-79c1473086b8----6-109------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) LangGraph + Gemini Pro + Custom Tool + Streamlit = Multi-Agent Application… In this post, you are going to learn how we can create this chatbot in LangGraph, Gemini Pro or any model you… zhaozhiming (https://medium.com/@zhaozhiming?source=email-2483a20590b9-1707327775011-digest.reader-440100e76000-9fad3bf352b6----7-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Generative AI (https://medium.com/generative-ai?source=email-2483a20590b9-1707327775011-digest.reader-440100e76000-9fad3bf352b6----7-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Evaluating RAG Applications with Trulens Currently, Retrieval Augmented Generation (RAG) applications based on Large Language Models (LLMs) are widely… Giuseppe Futia (https://medium.com/@giuseppefutia?source=email-2483a20590b9-1707327775011-digest.reader--0dfc39d2a893----8-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Building KGs with LLMs — The Use Case of the Rockefeller Archive Center How we used GPT to perform Named Entity Recognition, Relation Extraction, and Entity Resolution on… Chandan Durgia (https://medium.com/@durgiachandan?source=email-2483a20590b9-1707327775011-digest.reader--1fd9f64454a9----9-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Embedding: Types, Use cases and Evaluation (Part 3 of RAG Series) Making computers understand Text Alex Mathers (https://medium.com/@iamalexmathers?source=email-2483a20590b9-1707327775011-digest.reader--c3d5b3799c94----10-99------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Five ways you can be immune to the AI ‘threat’ in the coming years Don’t wake up in five years without income because A.I. Richardson stole your job. Sandeep Chavan (https://medium.com/@schavan_68898?source=email-2483a20590b9-1707327775011-digest.reader-e48f673dd523-d61e69702648----11-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Paktolus Engineering (https://medium.com/paktolus-engineering?source=email-2483a20590b9-1707327775011-digest.reader-e48f673dd523-d61e69702648----11-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Revolutionising Information Retrieval with Generative AI (Text-to-SQL) Introduction Suman Das (https://medium.com/@dassum?source=email-2483a20590b9-1707327775011-digest.reader--fb60abdeba07----12-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRA The field of natural language processing has been revolutionized by large language models (LLMs), which… Venkat Ram Rao (https://medium.com/@venkat.ramrao?source=email-2483a20590b9-1707327775011-digest.reader--981c732e92b0----13-98------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-1) Training an LLM Re-Ranker using Direct Preference Optimization Training Mistral 7B to be an LLM Re-ranker using human feedback. Edit who you follow (https://medium.com/me/following/people?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-31) LlamaIndex Newsletter 2024–01–30 Hello LlamaIndex Adventurers 🦙, LlamaIndex LlamaIndex Blog (https://medium.com/llamaindex-blog?source=email-2483a20590b9-1707327775011-digest.reader-d7683ed5043e-0d01eb0d8cef----0-2------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f-31) Control your recommendations (https://medium.com/me/missioncontrol?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Medium (https://medium.com/?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Unsubscribe (https://medium.com/me/email-settings/2483a20590b9/70e1f54132fc?type=social&source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Switch to the Weekly Digest (https://medium.com/me/email-settings/2483a20590b9/70e1f54132fc?type=social&preference=2&source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Careers (https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Help Center (https://help.medium.com/hc/en-us?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Privacy Policy (https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f) Terms of service (https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=email-2483a20590b9-1707327775011-digest.reader-------------------------b4ee6f77_9df0_4218_a348_b5c40ff9910f)\n"
     ]
    }
   ],
   "source": [
    "for page in bs_content:\n",
    "    print(page.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "def validation(url):\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    if parsed_url.scheme == \"https\" and parsed_url.netloc == \"medium.com\":\n",
    "            # 경로에서 @username 확인\n",
    "            path_parts = parsed_url.path.split('/')\n",
    "            if len(path_parts) >= 3 and path_parts[1].startswith('@'):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "url_dict = {}\n",
    "\n",
    "for link in links:\n",
    "    text = link.get_text(strip=True)\n",
    "    url = link.get('href').split(\"?\")[0]\n",
    "\n",
    "    if validation(url):\n",
    "        url_dict[url] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Parsing with Custom Pydantic Object\n",
    "class URL_TABLE(BaseModel):\n",
    "    url:str = Field(description=\"url\")\n",
    "    description:str = Field(description=\"description that describe url\")\n",
    "\n",
    "class URLTextList(BaseModel):\n",
    "    url_text_pairs: List[URL_TABLE]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=URLTextList)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "# parse result with PydanticOutputParser\n",
    "chain = llm | parser\n",
    "result = chain.invoke(f\"\"\"get dict {url_dict}. Show value and url if it is related to LLM or Python or Programming.\n",
    "    Output should be dictionary like this .\n",
    "    <Example output>                       \n",
    "                     {{\n",
    "    \"url_text_pairs\": [\n",
    "        {{\n",
    "            \"url\": \"https://example.com/1\",\n",
    "            \"description\": \"Example description 1\"\n",
    "        }},\n",
    "        {{\n",
    "            \"url\": \"https://example.com/2\",\n",
    "            \"description\": \"Example description 2\"\n",
    "        }}\n",
    "    ]}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url_text_pairs=[URL_TABLE(url='https://medium.com/@cobusgreyling/corrective-rag-crag-5e40467099f8', description='Corrective RAG (CRAG)By now, RAG is an accepted and well established standard for addressing data relevance for in-context…'), URL_TABLE(url='https://medium.com/@marcllopart/from-text-and-images-to-chat-transforming-data-into-conversations-with-pinecone-and-langchain-a57e196aff20', description='From text and images to Chat: Transforming data into conversations with…Transform text & images into chat: unleash AI with Pinecone & LangChain for dynamic data conversations.'), URL_TABLE(url='https://medium.com/@florian_algo/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7', description='Advanced RAG 03: Using RAGAs + LlamaIndex for RAG evaluationIn this article, we first introduce evaluation metrics for RAG proposed by RAGAs(Retrieval Augmented…'), URL_TABLE(url='https://medium.com/@zainbaq/querygpt-harnessing-generative-ai-to-query-your-data-with-natural-language-63fdfefaa888', description='QueryGPT\\u200a—\\u200aHarnessing Generative AI To Query Your Data With Natural Language.A prototype tool powered by Large Language Models to make querying your databases as easy as saying the word.'), URL_TABLE(url='https://medium.com/@dassum/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07', description='Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRAThe field of natural language processing has been revolutionized by large language models (LLMs), which…'), URL_TABLE(url='https://medium.com/@venkat.ramrao/training-an-llm-re-ranker-using-direct-preference-optimization-981c732e92b0', description='Training an LLM Re-Ranker using Direct Preference OptimizationTraining Mistral 7B to be an LLM Re-ranker using human feedback.')]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://medium.com/@cobusgreyling/corrective-rag-crag-5e40467099f8\n",
      "https://medium.com/@marcllopart/from-text-and-images-to-chat-transforming-data-into-conversations-with-pinecone-and-langchain-a57e196aff20\n",
      "https://medium.com/@florian_algo/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7\n",
      "https://medium.com/@zainbaq/querygpt-harnessing-generative-ai-to-query-your-data-with-natural-language-63fdfefaa888\n",
      "https://medium.com/@dassum/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07\n",
      "https://medium.com/@venkat.ramrao/training-an-llm-re-ranker-using-direct-preference-optimization-981c732e92b0\n"
     ]
    }
   ],
   "source": [
    "for content in result.url_text_pairs:\n",
    "    print(content.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your Today Daily LLM Digest!: 2024-02-13\n",
      "\n",
      "1. \"Corrective RAG (CRAG)By now, RAG is an accepted and well established standard for addressing data relevance for in-context…\" \n",
      "\t-url: https://medium.com/@cobusgreyling/corrective-rag-crag-5e40467099f8\n",
      "2. \"From text and images to Chat: Transforming data into conversations with…Transform text & images into chat: unleash AI with Pinecone & LangChain for dynamic data conversations.\" \n",
      "\t-url: https://medium.com/@marcllopart/from-text-and-images-to-chat-transforming-data-into-conversations-with-pinecone-and-langchain-a57e196aff20\n",
      "3. \"Advanced RAG 03: Using RAGAs + LlamaIndex for RAG evaluationIn this article, we first introduce evaluation metrics for RAG proposed by RAGAs(Retrieval Augmented…\" \n",
      "\t-url: https://medium.com/@florian_algo/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7\n",
      "4. \"QueryGPT — Harnessing Generative AI To Query Your Data With Natural Language.A prototype tool powered by Large Language Models to make querying your databases as easy as saying the word.\" \n",
      "\t-url: https://medium.com/@zainbaq/querygpt-harnessing-generative-ai-to-query-your-data-with-natural-language-63fdfefaa888\n",
      "5. \"Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRAThe field of natural language processing has been revolutionized by large language models (LLMs), which…\" \n",
      "\t-url: https://medium.com/@dassum/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07\n",
      "6. \"Training an LLM Re-Ranker using Direct Preference OptimizationTraining Mistral 7B to be an LLM Re-ranker using human feedback.\" \n",
      "\t-url: https://medium.com/@venkat.ramrao/training-an-llm-re-ranker-using-direct-preference-optimization-981c732e92b0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_format = f\"Here is your Today Daily LLM Digest!: {today}\\n\\n\"\n",
    "for idx, content in enumerate(result.url_text_pairs, 1):\n",
    "    prompt_format += f\"{idx}. \\\"{content.description}\\\" \\n\\t-url: {content.url}\\n\"\n",
    "print(prompt_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
