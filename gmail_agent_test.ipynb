{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "import base64\n",
    "import email\n",
    "import os\n",
    "\n",
    "from langchain_community.agent_toolkits import GmailToolkit\n",
    "from langchain_community.tools.gmail.utils import (\n",
    "    build_resource_service,\n",
    ")\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "\n",
    "def create_credentials():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # 사용자 인증이 필요한 경우\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # 다음 번 사용을 위해 인증된 사용자 정보를 저장\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "creds = create_credentials()\n",
    "api_resource = build_resource_service(credentials=creds)\n",
    "service = build('gmail', 'v1', credentials=creds)\n",
    "toolkit = GmailToolkit(api_resource=api_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GmailCreateDraft(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailSendMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailSearch(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailGetMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>),\n",
       " GmailGetThread(api_resource=<googleapiclient.discovery.Resource object at 0x000002399A2BFAF0>)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = toolkit.get_tools()\n",
    "tools # toolkit initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "instructions = \"\"\"You are an assistant. return output only.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, streaming=True, max_tokens=2048)\n",
    "agent = create_openai_functions_agent(llm, toolkit.get_tools(), prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=toolkit.get_tools(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent matching email ID: 18d85ba63be5cf84\n"
     ]
    }
   ],
   "source": [
    "search_result = agent_executor.invoke({\"input\": \"`search_gmail` with `{'query': 'from':'Medium Daily Digest', 'max_results': 1}`. Return Most recent matching mail with id ONLY.\"})\n",
    "print(search_result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18d85ba63be5cf84\n"
     ]
    }
   ],
   "source": [
    "search_result_output = search_result[\"output\"].split(\":\")[-1].lstrip(\" \") # parse result\n",
    "print(search_result_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message snippet: Rhcp Stories for Rhcp @rhcp1134·Become a member Medium daily digest Today&#39;s highlights Cobus Greyling Cobus Greyling· 5 min read Corrective RAG (CRAG) By now, RAG is an accepted and well\n"
     ]
    }
   ],
   "source": [
    "def get_message(service, user_id, message_id):\n",
    "    try:\n",
    "        message = service.users().messages().get(userId=user_id, id=message_id, format='raw').execute()\n",
    "        print('Message snippet: %s' % message['snippet'])\n",
    "\n",
    "        msg_str = base64.urlsafe_b64decode(message['raw'].encode('ASCII'))\n",
    "        mime_msg = email.message_from_bytes(msg_str)\n",
    "\n",
    "        # 메일 본문 찾기\n",
    "        if mime_msg.is_multipart():\n",
    "            for part in mime_msg.walk():\n",
    "                if part.get_content_type() == 'text/html':\n",
    "                    html_content = part.get_payload(decode=True).decode()\n",
    "                    break\n",
    "        else:\n",
    "            html_content = mime_msg.get_payload(decode=True).decode()\n",
    "\n",
    "        return html_content\n",
    "    except Exception as error:\n",
    "        print('An error occurred: %s' % error)\n",
    "\n",
    "# 메일 내용 가져오기 및 파싱 예제\n",
    "user_id = 'me'  # 현재 로그인한 사용자\n",
    "message_id = search_result_output  # 가져오고자 하는 메시지의 ID\n",
    "html_content = get_message(service, user_id, message_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "doc = Document(page_content=html_content)\n",
    "bs = BeautifulSoupTransformer()\n",
    "bs_content = bs.transform_documents(documents=[doc], tags_to_extract=[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "\n",
    "def validation(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.scheme == \"https\" and parsed_url.netloc == \"medium.com\":\n",
    "            # 경로에서 @username 확인\n",
    "            path_parts = parsed_url.path.split('/')\n",
    "            if len(path_parts) >= 3 and path_parts[1].startswith('@'):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "url_dict = {}\n",
    "\n",
    "for link in links:\n",
    "    text = link.get_text(strip=True)\n",
    "    url = link.get('href').split(\"?\")[0]\n",
    "\n",
    "    if validation(url):\n",
    "        url_dict[url] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Parsing with Custom Pydantic Object\n",
    "class URL_TABLE(BaseModel):\n",
    "    url:str = Field(description=\"url\")\n",
    "    description:str = Field(description=\"description that describe url\")\n",
    "\n",
    "class URLTextList(BaseModel):\n",
    "    url_text_pairs: List[URL_TABLE]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=URLTextList)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "# parse result with PydanticOutputParser\n",
    "chain = llm | parser\n",
    "result = chain.invoke(f\"\"\"get dict {url_dict}. Show value and url if it is related to LLM or Python or Programming.\n",
    "    Output should be dictionary like this .\n",
    "    <Example output>                       \n",
    "                     {{\n",
    "    \"url_text_pairs\": [\n",
    "        {{\n",
    "            \"url\": \"https://example.com/1\",\n",
    "            \"description\": \"Example description 1\"\n",
    "        }},\n",
    "        {{\n",
    "            \"url\": \"https://example.com/2\",\n",
    "            \"description\": \"Example description 2\"\n",
    "        }}\n",
    "    ]}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://medium.com/@cobusgreyling/corrective-rag-crag-5e40467099f8\n",
      "https://medium.com/@marcllopart/from-text-and-images-to-chat-transforming-data-into-conversations-with-pinecone-and-langchain-a57e196aff20\n",
      "https://medium.com/@florian_algo/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7\n",
      "https://medium.com/@zainbaq/querygpt-harnessing-generative-ai-to-query-your-data-with-natural-language-63fdfefaa888\n",
      "https://medium.com/@dassum/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07\n",
      "https://medium.com/@venkat.ramrao/training-an-llm-re-ranker-using-direct-preference-optimization-981c732e92b0\n"
     ]
    }
   ],
   "source": [
    "for content in result.url_text_pairs:\n",
    "    print(content.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your Today Daily LLM Digest!: 2024-02-13\n",
      "\n",
      "1. \"Corrective RAG (CRAG)By now, RAG is an accepted and well established standard for addressing data relevance for in-context…\" \n",
      "\t-url: https://medium.com/@cobusgreyling/corrective-rag-crag-5e40467099f8\n",
      "2. \"From text and images to Chat: Transforming data into conversations with…Transform text & images into chat: unleash AI with Pinecone & LangChain for dynamic data conversations.\" \n",
      "\t-url: https://medium.com/@marcllopart/from-text-and-images-to-chat-transforming-data-into-conversations-with-pinecone-and-langchain-a57e196aff20\n",
      "3. \"Advanced RAG 03: Using RAGAs + LlamaIndex for RAG evaluationIn this article, we first introduce evaluation metrics for RAG proposed by RAGAs(Retrieval Augmented…\" \n",
      "\t-url: https://medium.com/@florian_algo/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7\n",
      "4. \"QueryGPT — Harnessing Generative AI To Query Your Data With Natural Language.A prototype tool powered by Large Language Models to make querying your databases as easy as saying the word.\" \n",
      "\t-url: https://medium.com/@zainbaq/querygpt-harnessing-generative-ai-to-query-your-data-with-natural-language-63fdfefaa888\n",
      "5. \"Fine Tune Large Language Model (LLM) on a Custom Dataset with QLoRAThe field of natural language processing has been revolutionized by large language models (LLMs), which…\" \n",
      "\t-url: https://medium.com/@dassum/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07\n",
      "6. \"Training an LLM Re-Ranker using Direct Preference OptimizationTraining Mistral 7B to be an LLM Re-ranker using human feedback.\" \n",
      "\t-url: https://medium.com/@venkat.ramrao/training-an-llm-re-ranker-using-direct-preference-optimization-981c732e92b0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_format = f\"Here is your Today Daily LLM Digest!: {today}\\n\\n\"\n",
    "for idx, content in enumerate(result.url_text_pairs, 1):\n",
    "    prompt_format += f\"{idx}. \\\"{content.description}\\\" \\n\\t-url: {content.url}\\n\"\n",
    "print(prompt_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
